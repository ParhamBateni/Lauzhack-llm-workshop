{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Integrating LLMs into Your Projects: A Practical Guide"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run this notebook, add your Hugging Face API token (`HF_TOKEN`) and OpenAI API key (`OPENAI_API_KEY`) to the `.env` file in the project root.\n",
        "These credentials enable access to inference APIs. Some Hugging Face models may work without a token, \n",
        "but others require authentication even for downloads. For OpenAI and Langchain usage, the OpenAI API key is mandatory. The following cell loads the environment variables from the `.env` file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eC90kGhlsjES",
        "outputId": "93f7e835-cd8b-48de-ac3f-bf793c150b60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XcGExgPnI_7"
      },
      "source": [
        "# Huggingface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Jrk_FvH3vJC"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "LLM models are trained on large volumes of text converted into tokens. To generate text with an LLM, we need a tokenizer (to convert input text to tokens) and a fine-tuned LLM model itself.\n",
        "The Hugging Face `transformers` library provides both tokenizer and model implementations for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLqE8WI_uPQu",
        "outputId": "6cb776a6-35b6-4541-c082-ef0b32ec4b58"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "# TODO: add the code here\n",
        "# First use the tokenizer to encode the text and then the model to generate the output \n",
        "# and finally decode the output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a1fdada"
      },
      "source": [
        "The `pipeline` function is a high-level abstraction that makes it easy to use pre-trained models for various tasks. Here are a few examples:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZjUN2ohqB7l"
      },
      "source": [
        "### Text Generation\n",
        "\n",
        "This example shows how to generate text using the OpenAI API. You can specify the model to use and provide a prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0GokWbNnFSK",
        "outputId": "96816b7b-9412-4b7b-89eb-9918d3beab1a"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "set_seed(44)\n",
        "# TODO: add the code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2beb68da"
      },
      "source": [
        "### Sentiment Analysis\n",
        "This task classifies text into positive or negative sentiment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47cd0530",
        "outputId": "01e7236a-4f2a-48bd-cd95-34e5fc1a0159"
      },
      "outputs": [],
      "source": [
        "# TODO: add the code here\n",
        "# Try \"Ce film est vraiment mauvais\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c57e800"
      },
      "source": [
        "### Translation\n",
        "This task translates text from one language to another."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce2088b5",
        "outputId": "78e85308-cc69-4d60-fad4-3cf0d22e65b3"
      },
      "outputs": [],
      "source": [
        "# TODO: add the code here\n",
        "# Using a pre-trained model for translation (English to French)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDef7cJW2cw-"
      },
      "source": [
        "# OpenAI\n",
        "\n",
        "Let's explore how to use the OpenAI API for various tasks. You will need an OpenAI API key to run these examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "g2RAYEHT9-d-"
      },
      "outputs": [],
      "source": [
        "!pip install openai --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "openai_key = os.getenv(\"OPENAI_KEY\") # put your openai key here as a string. Example: \"sk-proj-1234567890\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "kc9V_8xq-fA5",
        "outputId": "c06a525c-c768-4752-b9fe-d6f2c94d12a8"
      },
      "outputs": [],
      "source": [
        "from openai import OpenAI\n",
        "# TODO: add the code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvqHOTiO5dS3"
      },
      "source": [
        "### Image Understanding\n",
        "\n",
        "This example demonstrates how to use the OpenAI API to understand the content of an image by providing an image URL."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gE_VFg723vJH",
        "outputId": "931fd183-324e-4f4c-d0c1-4154fc82920f"
      },
      "outputs": [],
      "source": [
        "# TODO: add the code here\n",
        "# try to ask the model to describe the image at this url: \n",
        "# https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Cat_November_2010-1a.jpg/500px-Cat_November_2010-1a.jpg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbZJ_V_h5rRp"
      },
      "source": [
        "### Conversational AI\n",
        "\n",
        "This example shows how to build a simple conversational AI using the OpenAI API by creating a loop to take user input and generate responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "6bh0WeMC-0xq",
        "outputId": "78c94940-93a5-4d6a-b9cd-df07ec922089"
      },
      "outputs": [],
      "source": [
        "# TODO: add the code here\n",
        "# add a loop to take user input and generate responses\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMIUGkub4trd"
      },
      "source": [
        "# Langchain\n",
        "\n",
        "Langchain is a framework for developing applications powered by language models. It provides tools and abstractions to chain together different components, such as language models, prompts, and data sources."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9312cc49"
      },
      "outputs": [],
      "source": [
        "# Install Langchain\n",
        "!pip install requests langchain langchain-core langchain-openai --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffbade12"
      },
      "source": [
        "### Simple LLM Chain\n",
        "\n",
        "This example shows how to create a simple chain to interact with a language model using Langchain. It defines a prompt template and uses an LLMChain to run the prompt through the language model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        },
        "id": "4db0e9f6",
        "outputId": "36827291-aa7b-48d7-8bdf-01d6aafa8b09"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "# TODO: add the code here\n",
        "# Make a chain of llm and prompt template that asks the user to input a name and \n",
        "# then generate a short marketing slogan for a company called that name\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9891f9b0"
      },
      "source": [
        "### Using a sequential chain\n",
        "\n",
        "This example shows how to use a sequential chain in Langchain to combine multiple steps. The output of one chain becomes the input of the next chain in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "303f4818",
        "outputId": "469cb62d-7e77-40c9-dddd-cee1606b8ee7"
      },
      "outputs": [],
      "source": [
        "# TODO: add the code here\n",
        "# Make a sequential chain of llm and prompt template that asks the user to input a name and \n",
        "# then generate a short marketing slogan for a company called that name\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
